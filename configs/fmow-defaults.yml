# Saving setup
algorithm: erm
phase: train
save_folder: /mnt/data/acorso/results/

# Training dataset information
data_dir: /scratch/users/acorso/data/
n_classes: 62
train_dataset: fmow-train
size: [224, 224]
n_channels: 3
train_transforms: []
eval_transforms: [wilds_default_normalization]
# These are for scaling the performance:
min_performance: 0.
max_performance: 1.0

# Parameters controlling resources
max_num_workers: 32
accelerator: gpu
devices: 1

# Training params - (Many of these are likely going to be tuned)
max_epochs: 60
lr: 0.001
batch_size: 128
optimizer: adam
model_source: torchvision
model: densenet121
label_smoothing: 0.0
pretrained_weights: DEFAULT
freeze_weights: False
unfreeze_k_layers: 0
calibration_method: none # options are none, temperature_scaling

# HRE setup
val_id_dataset: fmow-id_val
val_ds_datasets:
  - fmow-val
  - fmow-id_val-corruption1_val
val_ood_datasets:
  - gaussian_noise
  - iwildcam-id_val
  - rxrx1-id_val
  - camelyon17-id_val
test_id_dataset: fmow-id_test
test_ds_datasets:
  - fmow-test
  - fmow-id_test-corruption1_test
test_ood_datasets:
  - gaussian_noise
  - iwildcam-id_test
  - rxrx1-id_test
  - camelyon17-id_test
val_dataset_length: 1024
test_dataset_length: 1024
num_adv: 128
w_perf: 0.2
w_rob: 0.2
w_sec: 0.2
w_cal: 0.2
w_oodd: 0.2
